= Smart Testing
:numbered:
:sectlink:
:sectanchors:
:sectid:
:source-language: java
:source-highlighter: coderay
:sectnums:
:icons: font
:toc: left
:smart-testing-version: 0.0.1

*We know which tests you want to run.*

We all know that as the project evolves we keep adding more and more tests to ship our products confidently. This however has
an impact on the build time and thus we waste time waiting for the most important question to be answered - "Did I break anything with my changes?".

Let it be your local development or a CI server - what if you could know this as soon as possible?

We created *Smart Testing* to give you the fastest possible feedback loop when it comes to executing your tests.

== Preparation of the Environment

First thing you need to do to do this workshop if to have installed on your machine next software:

* `git` client to clone project example.
* `Java 8` is the minimum Java version required.
* `Maven` installed and in `PATH` directory. We recommend version `3.5.0` of `Maven` but any `3.3.X` version works as well.
Although it has not been tested it should still be possible to run with any version of `3.X`.
* `Jenkins 2.73.1` installed with Jenkins Pipeline (which comes with suggested plugins) and optionally Blue Ocean (https://jenkins.io/projects/blueocean/).

== Building the project
=== Cloning the example project and running the build

Open a terminal and just clone `VertX Calculator` repository:

....
git clone git@github.com:lordofthejars/vertxcalculator.git
....

Then just go inside `vertxcalculator` directory and run the tests with `Maven`.

....
mvn clean test
....

.Output
....
...
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.superbiz.CalculatorDecoratorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.227 sec
Running org.superbiz.CalculatorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.058 sec
Running org.superbiz.CalculatorVerticleTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.107 sec
Running org.superbiz.InfrastructureTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.044 sec
Running org.superbiz.MatrixCalculatorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.056 sec

Results :

Tests run: 6, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 7.864 s
....

Not a long build, but if you think about a bigger project this time might be from 1 minute to 5 minutes.

INFO: In current project 6 test methods are executed.

=== Adding a new test case

Now let's add a new test case.
Open `org.superbiz.CalculatorTest` and add next content:

[source, java]
.src/main/java/org/superbiz/CalculatorTest.java
----
@Test
public void should_subtract_when_negative() {

  // given
  Calculator calculator = new Calculator();

  // when
  final int result = calculator.add(1, -3);

  // then
  assertThat(result).isEqualTo(2);
}
----

And then just run again test goal again:

....
mvn clean test
....

Then the build is started and after waiting the whole build, it fails.

.Output
....
...
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.superbiz.CalculatorDecoratorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.128 sec
Running org.superbiz.CalculatorTest
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.047 sec <<< FAILURE!
should_subtract_when_negative(org.superbiz.CalculatorTest)  Time elapsed: 0.039 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[]2> but was:<[-]2>
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at org.superbiz.CalculatorTest.should_subtract_when_negative(CalculatorTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running org.superbiz.CalculatorVerticleTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.651 sec
Running org.superbiz.InfrastructureTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.04 sec
Running org.superbiz.MatrixCalculatorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.041 sec

Results :

Failed tests:   should_subtract_when_negative(org.superbiz.CalculatorTest): expected:<[]2> but was:<[-]2>

Tests run: 7, Failures: 1, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
....

Now it is only about seconds but think about in bigger projects were instead of seconds you need to wait minutes.

INFO: Now 7 test methods are executed.

So if we know that we have just added a new test case, why not running the test class containing it, instead of running all tests?

This is exactly what *Smart Testing* does among other features.

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] Need to wait until build finishes to get failures.
* [*] Sometimes you already know which tests should be run.

== Smart Testing
=== Installing Smart Testing

Smart Testing is a Maven extension, not a Maven plugin, and this means that using it is slightly different than registering a plugin.

You can read all the details on how to do it at http://arquillian.org/smart-testing/#_maven_extension but the quick way of registering Smart Testing is just executing  `curl -sSL https://git.io/vdv4j | bash` on project root directory.

Then you need to update/force the surefire version.
For this case we are going to force to use the latest one `2.20`.

So let's open `pom.xml` file and register latest `surefire` version:

[source, xml]
.pom.xml
----
<plugin>
  <artifactId>maven-surefire-plugin</artifactId>
  <version>2.20</version>
</plugin>
----

=== Running Smart Testing

Now it is time to run build but with *Smart Testing* enabled.

....
mvn clean test -Dsmart.testing="new, changed"
....

And now the build still fails but it only executes the modified test instead of all tests.

.Output
....
INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorTest
[ERROR] Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.074 s <<< FAILURE! - in org.superbiz.CalculatorTest
[ERROR] should_subtract_when_negative(org.superbiz.CalculatorTest)  Time elapsed: 0.067 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[]2> but was:<[-]2>
	at org.superbiz.CalculatorTest.should_subtract_when_negative(CalculatorTest.java:33)

[INFO]
[INFO] Results:
[INFO]
[ERROR] Failures:
[ERROR]   CalculatorTest.should_subtract_when_negative:33 expected:<[]2> but was:<[-]2>
[INFO]
[ERROR] Tests run: 3, Failures: 1, Errors: 0, Skipped: 0
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
....

Now not all tests are executed but just the ones we've modified previously.

==== Explanation of `smart.testing` property

But how do we know which tests are important and which ones not?
In previous example the important tests are those *tests* that has been added or modified in Git repo as local changes.

There are several strategies that you can choose from which determine what are the *important* tests.
Currently we have following strategies in place: `new`, `changed`, `affected` and `failed`.

To set them you need to set Java system property `smart.testing` to one or more strategies in comma-separated value form.

Currently next strategies has been used:

new strategy:: uses SCM information (currently only Git is supported) to detect new tests and treat them as important tests.
changed strategy:: is like `new` strategy, but it uses only tests that are modified.

In next sections we are going to see other strategies.

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] Smart Testing can run only new or modified tests
* [*] There are several strategies to choose from

=== Fixing the build

Let's fix the failing test, by setting the correct order in expected list:

[source, java]
.src/main/java/org/superbiz/CalculatorTest.java
----
@Test
public void should_subtract_when_negative() {

  // given
  Calculator calculator = new Calculator();

  // when
  final int result = calculator.add(1, -3);

  // then
  assertThat(result).isEqualTo(-2);
}
----

Obviously now if you run again Smart Testing you'll get a build passed as result:

....
mvn clean test -Dsmart.testing="new, changed"
....

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.142 s - in org.superbiz.CalculatorTest
[INFO]
[INFO] Results:
[INFO]
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
....

Now let's commit all changes:

....
git add .
git commit -m "Adds new test case"
....

And run again the build:

....
mvn clean test -Dsmart.testing="new, changed"
....

And the output is:

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO]
[INFO] Results:
[INFO
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
....

Notice that no tests are executed.
The answer of this behaviour is that `new` and `changed` strategies in Smart Testing check by default local changes and not committed changes.
We'll learn in next sections how to change this.

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] `new` and `changed` strategies uses only Git local changes to detect new and modified tests.

=== Modifying business code

So far we've seen how `new` and `changed` strategies works with tests.
Of course this works in cases where you only create or modify a new test.
But what's happening if what you are modifying is a business class instead of a test?

Open `org.superbiz.Calculator` class and let's implement correctly the `multiply` method:

[source, java]
.src/main/java/org/superbiz/Calculator.java
----
public int multiply(int a, int b) {
  return a * b;
}
----

And now do the same you did before by running Smart Testing with `new` and `changed` strategy.

....
mvn clean test -Dsmart.testing="new, changed"
....

And the output is:

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO]
[INFO] Results:
[INFO]
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
....

So why there are not tests run?
The answer is that `new` and `changed` strategies just look for *tests* that are new or modified, but in this case we've not modified any test, but business code.

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] `new` and `changed` strategies detect only test changes, not business code changes.

=== `affected` strategy

Let's see `affected` strategy that deals with this use case.

Now run next command, which configures `affected` strategy.

....
mvn clean test -Dsmart.testing="affected"
....

and the output is:

.Output
....
INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorTest
[ERROR] Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.09 s <<< FAILURE! - in org.superbiz.CalculatorTest
[ERROR] should_multiply_two_numbers(org.superbiz.CalculatorTest)  Time elapsed: 0.008 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[0]> but was:<[3]>
	at org.superbiz.CalculatorTest.should_multiply_two_numbers(CalculatorTest.java:46)

[INFO] Running org.superbiz.InfrastructureTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.517 s - in org.superbiz.InfrastructureTest
[INFO] Running org.superbiz.CalculatorVerticleTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.1 s - in org.superbiz.CalculatorVerticleTest
[INFO] Running org.superbiz.CalculatorDecoratorTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in org.superbiz.CalculatorDecoratorTest
[INFO]
[INFO] Results:
[INFO]
[ERROR] Failures:
[ERROR]   CalculatorTest.should_multiply_two_numbers:46 expected:<[0]> but was:<[3]>
[INFO]
[ERROR] Tests run: 6, Failures: 1, Errors: 0, Skipped: 0
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
....

Notice that now some tests has been run, not all of them since the whole project has _7_ tests and now it has executed _6_, but why this number?

==== Explanation of `affected` strategy

`Affected` strategy uses a different approach to choose what are the important tests to run.
This strategy also relies on SCM information but in this case it retrieves any new or modified business class.

When this strategy gets all changes then inspect all tests of current project checking which ones imports these classes.
If the test exercises a business class that has been modified, we treat it as important so it will be executed earlier in the test plan.

But `affected` strategy not just get direct imports, but also the applies a transitivity to these imports.
Suppose we have `ATest.java` which imports `A.java`.
At the same time `A.java` imports `B.java` (ATest -> A -> B). If `B.java` is modified, then `ATest.java is considered an important test too.

And for this reason so many tests are considered important for a single change.

==== Prune search tree

In Smart Testing we support three ways to control transitivity:

* inclusions
* exclusions
* disable transitivity

For this case we are going to disable transitivity, so only tests that directly imports `org.superbiz.Calculator` are run.

Run next command, with `affected` strategy and disabling transitivity.

....
mvn -Dsmart.testing="affected" -Dsmart.testing.affected.transitivity=false clean test
....

and the output is:

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorTest
[ERROR] Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.09 s <<< FAILURE! - in org.superbiz.CalculatorTest
[ERROR] should_multiply_two_numbers(org.superbiz.CalculatorTest)  Time elapsed: 0.008 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[0]> but was:<[3]>
	at org.superbiz.CalculatorTest.should_multiply_two_numbers(CalculatorTest.java:46)
....

In this concrete example to make `selective` mode useful we have disabled transitivity.
In other cases (usually when using external libraries) you will like to exclude these packages or just including current project package.
But of course it will depend on how you structure your project that you might need no prune or a concrete prune strategy.

Let's fix the test:

[source, java]
.src/main/java/org/superbiz/CalculatorTest.java
----
@Test
public void should_multiply_two_numbers() {

  // given
  Calculator calculator = new Calculator();

  // when
  final int result = calculator.multiply(1, 3);

  // then
  assertThat(result).isEqualTo(3);

}
----

Finally let's commit all changes we have done:

....
git add .
git commit -m "Fix multiply method"
....

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] `affected` strategy is used to get changes from business code and detect tests related to this part
* [*] `affected` strategy uses _imports_ to get which tests to execute
* [*] It scans transitivitly all imports by default (excluding `java` package)
* [*] You can prune import graph by using _inclusions_, _exclusions_ or disabling it.

=== `ordering` mode

So far we've been using all the time the `selecting` mode, but Smart Testing also supports `ordering` mode.
Let's add a new test case and run Smart Testing in `ordering` mode.

=== Adding a new test case

Now let's add a new test case.
Open `org.superbiz.CalculatorDecoratorTest` and add next content:

[[sets_test]]
[source, java]
.src/main/java/org/superbiz/CalculatorDecoratorTest.java
----
@Test
public void should_decorate_sum_with_negatives() {

  // given
  CalculatorDecorator calculatorDecorator = new CalculatorDecorator();

  // when
  final String result = calculatorDecorator.add(1, -1);

  // then
  assertThat(result).isEqualTo("1 + 1 = 0");
}
----

And then just run again test goal again but configuring smart testing to run in `ordering` mode:

....
mvn -Dsmart.testing="new, changed" -Dsmart.testing.mode="ordering" clean test
....

You'll see next output at the beginning of testing phase:

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorDecoratorTest
[ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.079 s <<< FAILURE! - in org.superbiz.CalculatorDecoratorTest
[ERROR] should_decorate_sum_with_negatives(org.superbiz.CalculatorDecoratorTest)  Time elapsed: 0.056 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<"1 + []1 = 0"> but was:<"1 + [-]1 = 0">
	at org.superbiz.CalculatorDecoratorTest.should_decorate_sum_with_negatives(CalculatorDecoratorTest.java:32)

[INFO] Running org.superbiz.CalculatorTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in org.superbiz.CalculatorTest
[INFO] Running org.superbiz.CalculatorVerticleTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.399 s - in org.superbiz.CalculatorVerticleTest
[INFO] Running org.superbiz.InfrastructureTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.04 s - in org.superbiz.InfrastructureTest
[INFO] Running org.superbiz.MatrixCalculatorTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.053 s - in org.superbiz.MatrixCalculatorTest
[INFO]
[INFO] Results:
[INFO]
[ERROR] Failures:
[ERROR]   CalculatorDecoratorTest.should_decorate_sum_with_negatives:32 expected:<"1 + []1 = 0"> but was:<"1 + [-]1 = 0">
[INFO]
[ERROR] Tests run: 8, Failures: 1, Errors: 0, Skipped: 0
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
....

Notice that first test run is the one that we have modified.
But the big difference with `selecting` mode is that now other tests are run as well.

==== Explanation of `ordering` mode

`ordering` mode as its name suggests orders the test execution plan so important tests are executed first and then the rest.

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] `ordering` mode runs all tests given high priority to *important* tests

=== Aborting build

So as you can see in previous new test case, it is executed first but the build continues its execution.
This happens because by default Maven aborts the build because of a failure _per-module_, this means that in case of single module projects there is no big difference between running Smart Testing in `ordering` mode or just disable Smart Testing.

Maven Surefire plugin offers a configuration option to set after how many failures the build should be skipped.
This property is `skipAfterFailureCount`.

TIP: You can read more about this configuration parameter at http://maven.apache.org/surefire/maven-surefire-plugin/examples/skip-after-failure.html

Let's update surefire configuration:

[source, xml]
.pom.xml
----
<plugin>
  <artifactId>maven-surefire-plugin</artifactId>
  <version>2.20</version>
  <configuration>
    <skipAfterFailureCount>1</skipAfterFailureCount>
  </configuration>
</plugin>
----

And then run again the build:

....
mvn -Dsmart.testing="new, changed" -Dsmart.testing.mode="ordering" clean test
....

And the output should look like:

.Output
....
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.superbiz.CalculatorDecoratorTest
[ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 0.045 s <<< FAILURE! - in org.superbiz.CalculatorDecoratorTest
[ERROR] should_decorate_sum_with_negatives(org.superbiz.CalculatorDecoratorTest)  Time elapsed: 0.036 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<"1 + []1 = 0"> but was:<"1 + [-]1 = 0">
	at org.superbiz.CalculatorDecoratorTest.should_decorate_sum_with_negatives(CalculatorDecoratorTest.java:32)

[INFO] Running org.superbiz.CalculatorTest
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 s - in org.superbiz.CalculatorTest
[INFO] Running org.superbiz.CalculatorVerticleTest
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 s - in org.superbiz.CalculatorVerticleTest
[INFO] Running org.superbiz.InfrastructureTest
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 s - in org.superbiz.InfrastructureTest
[INFO] Running org.superbiz.MatrixCalculatorTest
[WARNING] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 s - in org.superbiz.MatrixCalculatorTest
[INFO]
[INFO] Results:
[INFO]
[ERROR] Failures:
[ERROR]   CalculatorDecoratorTest.should_decorate_sum_with_negatives:32 expected:<"1 + []1 = 0"> but was:<"1 + [-]1 = 0">
[INFO]
[ERROR] Tests run: 6, Failures: 1, Errors: 0, Skipped: 5
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
....

Now when the first test case fails, the remaining test cases are _skipped_.
Notice that now all tests after the failure are just skipped.

Let's fix the error and commit the changes:

[source, java]
.src/main/java/org/superbiz/CalculatorDecoratorTest.java
----
@Test
public void should_decorate_sum_with_negatives() {

  // given
  CalculatorDecorator calculatorDecorator = new CalculatorDecorator();

  // when
  final String result = calculatorDecorator.add(1, -1);

  // then
  assertThat(result).isEqualTo("1 + -1 = 0");
}
----

....
git add .
git commit -m "Add test case"
....

:numbered!:
=== icon:check-square-o[] Check point
:numbered:

You've learnt:

* [*] `ordering` mode runs all tests given high priority to *important* tests
* [*] `skipAfterFailureCount` surefire property can be used to skip tests in case of failure

== Continuous Integration / Continuous Delivery

So far you’ve seen how to use Smart Testing from developer perspective (running on local machine). But ultimately your software is going to be built on CI/CD server and saving time there means more resources for other projects.

One of important things to take into consideration is that meanwhile on the developer’s machine selecting mode might be the one used most frequently, in CI/CD environment you *should* consider executing the build in the ordering mode at some point (let it be regular build or a step in the pipeline).

In case of development machine, you’ll probably want to build simply against the local changes, but in case of CI/CD environment, probably the changes you want to take into consideration are those between the commits you are going to run the build.

Let’s see how to configure Smart Testing in Jenkins Pipeline.

=== Jenkinsfile

`Jenkinsfile` is the _de-facto_ file name where you defines the pipeline.

Let's create a `jenkinsfile` at project root directory with next content:
